{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pickle\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import dlib\n",
    "from skimage import io\n",
    "import cv2\n",
    "import os\n",
    "from datetime import datetime\n",
    "import csv\n",
    "\n",
    "# Initialize face detector, shape predictor, and face recognition model\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "shape_predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")  # Adjust the path as needed\n",
    "face_recognizer = dlib.face_recognition_model_v1(\"dlib_face_recognition_resnet_model_v1.dat\")  # Adjust the path as needed\n",
    "\n",
    "def get_face_encoding(file_path):\n",
    "    image = io.imread(file_path)\n",
    "    \n",
    "    # Sử dụng dlib để lấy mã hóa khuôn mặt\n",
    "    dets = detector(image, 1)\n",
    "    if len(dets) > 0:\n",
    "        shape = shape_predictor(image, dets[0])\n",
    "        face_descriptor = face_recognizer.compute_face_descriptor(image, shape)\n",
    "\n",
    "        # Convert dlib vector to a NumPy array and then to a list\n",
    "        face_descriptor_list = np.array(face_descriptor).tolist()\n",
    "\n",
    "        return face_descriptor_list\n",
    "    else:\n",
    "        return None\n",
    "def classify_faces(source_folder,face_encoding):\n",
    "    # Load the DataFrame from the JSON file\n",
    "    df = pd.read_json(source_folder)\n",
    "    classify_faces_array=[]\n",
    "    for index in range(len(df)):\n",
    "        face_encoding_in_df  = df['encode'].iloc[index]\n",
    "        \n",
    "        if len(face_encoding_in_df):\n",
    "            # Check if there's a folder for this person\n",
    "                face_encoding_df = np.array(face_encoding_in_df)\n",
    "                face_encoding_testing = np.array(face_encoding)\n",
    "\n",
    "                # Compare encodings to determine if it belongs to the same person\n",
    "                if cv2.norm(face_encoding_df, face_encoding_testing, cv2.NORM_L2) < 0.4:\n",
    "                    classify_faces_array.append(df['name'].iloc[index])\n",
    "                    \n",
    "     \n",
    "    return classify_faces_array\n",
    "\n",
    "# graph_file_path = f'saved_graph_{QUANLITY}.pkl'\n",
    "\n",
    "# with open(graph_file_path, 'rb') as file:\n",
    "#     G = pickle.load(file)\n",
    "\n",
    "# result = []\n",
    "# for target_node in photo_cropped:\n",
    "#     related_nodes = [node for node in G.neighbors(target_node)]\n",
    "#     result.append({\"meta\": {\"croppedId\": target_node}, \"results\": [{\"photoName\": node} for node in related_nodes]})\n",
    "\n",
    "# with open(f'{PATH_DIR}{RESULT_GNN_FILE_NAME}.txt', 'w') as file:\n",
    "#     json.dump(result, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\19521\\OneDrive\\Desktop\\Optimization-Solution\\IMPROVE_PERFORMANCE\\predict.ipynb Cell 2\u001b[0m line \u001b[0;36m9\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/19521/OneDrive/Desktop/Optimization-Solution/IMPROVE_PERFORMANCE/predict.ipynb#W1sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mfor\u001b[39;00m photo \u001b[39min\u001b[39;00m photos:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/19521/OneDrive/Desktop/Optimization-Solution/IMPROVE_PERFORMANCE/predict.ipynb#W1sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m   photo_test_path\u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(IMAGE_PATH,photo)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/19521/OneDrive/Desktop/Optimization-Solution/IMPROVE_PERFORMANCE/predict.ipynb#W1sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m   face_encoding \u001b[39m=\u001b[39m get_face_encoding(photo_test_path) \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/19521/OneDrive/Desktop/Optimization-Solution/IMPROVE_PERFORMANCE/predict.ipynb#W1sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m   \u001b[39mif\u001b[39;00m face_encoding\u001b[39m!=\u001b[39m\u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/19521/OneDrive/Desktop/Optimization-Solution/IMPROVE_PERFORMANCE/predict.ipynb#W1sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     start_time_class \u001b[39m=\u001b[39m datetime\u001b[39m.\u001b[39mnow()\n",
      "\u001b[1;32mc:\\Users\\19521\\OneDrive\\Desktop\\Optimization-Solution\\IMPROVE_PERFORMANCE\\predict.ipynb Cell 2\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/19521/OneDrive/Desktop/Optimization-Solution/IMPROVE_PERFORMANCE/predict.ipynb#W1sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     face_descriptor \u001b[39m=\u001b[39m face_recognizer\u001b[39m.\u001b[39mcompute_face_descriptor(image, shape)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/19521/OneDrive/Desktop/Optimization-Solution/IMPROVE_PERFORMANCE/predict.ipynb#W1sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m     \u001b[39m# Convert dlib vector to a NumPy array and then to a list\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/19521/OneDrive/Desktop/Optimization-Solution/IMPROVE_PERFORMANCE/predict.ipynb#W1sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m     face_descriptor_list \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49marray(face_descriptor)\u001b[39m.\u001b[39mtolist()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/19521/OneDrive/Desktop/Optimization-Solution/IMPROVE_PERFORMANCE/predict.ipynb#W1sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m face_descriptor_list\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/19521/OneDrive/Desktop/Optimization-Solution/IMPROVE_PERFORMANCE/predict.ipynb#W1sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "QUANLITY='cropped_test'\n",
    "SOURCE_FOLDER=f'./crop_face_encode_1080.json'\n",
    "IMAGE_PATH= './cropped_test/'\n",
    "photos= os.listdir(IMAGE_PATH)\n",
    "photo_cropped_id_df=[]\n",
    "for photo in photos:\n",
    "  photo_test_path= os.path.join(IMAGE_PATH,photo)\n",
    "\n",
    "  face_encoding = get_face_encoding(photo_test_path) \n",
    "  if face_encoding!=None:\n",
    "    start_time_class = datetime.now()\n",
    "    photo_cropped_ids = classify_faces(SOURCE_FOLDER,face_encoding)\n",
    "    end_time_class = datetime.now()\n",
    "    photo_cropped_id_df.append({\n",
    "      \"photo\":photo,\n",
    "      \"photo_cropped_ids\":photo_cropped_ids,\n",
    "      \"start_time_class\":start_time_class,\n",
    "      \"end_time_class\":end_time_class\n",
    "      })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "graph_file_path = f'saved_graph_1080.pkl'\n",
    "\n",
    "with open(graph_file_path, 'rb') as file:\n",
    "    G = pickle.load(file)\n",
    "    # print(G.nodes())\n",
    "df =[]\n",
    "\n",
    "for photo_cropped in photo_cropped_id_df:\n",
    "    result=[]\n",
    "    photo_cropped_ids = photo_cropped['photo_cropped_ids']\n",
    "    photo_test_name=photo_cropped['photo']\n",
    "    start_time_class=photo_cropped['start_time_class']\n",
    "    end_time_class=photo_cropped['end_time_class']\n",
    "    start_test = datetime.now()\n",
    "    for target_node in photo_cropped_ids:\n",
    "         # Data testing\n",
    "        start_time = datetime.now()\n",
    "        related_nodes = [node for node in G.neighbors(target_node)]\n",
    "        actual = related_nodes\n",
    "        # Get the end time\n",
    "        end_time = datetime.now()\n",
    "        # Calculate the duration\n",
    "        duration = end_time - start_time\n",
    "        photo_name_node = target_node\n",
    "        result.append(\n",
    "        {\n",
    "        \"target_node\": target_node,\n",
    "        \"results\": [{\"photoName\": node} for node in related_nodes],\n",
    "        'start_time':start_time,\n",
    "        'end_time':end_time,  \n",
    "        })\n",
    "    end_test = datetime.now()\n",
    "    time_cropped= abs((start_time_class-end_time_class).total_seconds() )\n",
    "    time_predict= abs((start_test-end_test).total_seconds() )\n",
    "    total_time=time_cropped+time_predict\n",
    "    df.append({\n",
    "        'photo_test_name':photo_test_name,\n",
    "        'time_cropped':time_cropped,\n",
    "        'time_predict':time_predict,\n",
    "        'total_time':total_time,\n",
    "        'result':result   \n",
    "        })\n",
    "\n",
    "df_json = pd.DataFrame(df)\n",
    "df_json.to_json(f'result_{1080}.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
